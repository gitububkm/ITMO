# -*- coding: utf-8 -*-
"""СМИИ_ЛР3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tQyVzi8OHeNK4m1eBEaPZnORA2L6Xw_i

### **Лабораторная Работа №3**
"""

# Импортируем все необходимые инструменты для нашего исследования
import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
import seaborn as sns

# Устанавливаем стиль графиков для лучшей читаемости
sns.set(style="whitegrid", font_scale=1.1)
plt.rcParams['figure.figsize'] = (12, 7)

# Загружаем наши подготовленные данные из CSV файлов
# --- Для Задачи 1 ---
df1_2025 = pd.read_csv('task1_part1-2_data_2025.csv')
df1_multiyear = pd.read_csv('task1_part3_data_2023-2025.csv')
# --- Для Задачи 2 ---
df2_cwe = pd.read_csv('task2_correlation_cwe_2025.csv')
# --- Для Задачи 3 ---
df3_vendors = pd.read_csv('task3_correlation_vendors_2025.csv')

print("--- Данные для Задачи 1 (2025 год) ---")
print(df1_2025.head(), "\n")
print("--- Данные для Задачи 1 (2023-2025) ---")
print(df1_multiyear.head(), "\n")
print("--- Данные для Задачи 2 ---")
print(df2_cwe.head(), "\n")
print("--- Данные для Задачи 3 ---")
print(df3_vendors.head(), "\n")

# Цель: выяснить, как каждый фактор ПО ОТДЕЛЬНОСТИ влияет на число уязвимостей.

print("\n" + "="*50)
print(" ЗАДАЧА 1.1: АНАЛИЗ ВЛИЯНИЯ КАЖДОГО ФАКТОРА")
print("="*50 + "\n")

# --- Анализ влияния фактора 'Тип ПО' ---
# Фильтруем данные, чтобы остались только строки, относящиеся к типам ПО
df_soft_types = df1_2025[df1_2025['Factor_Category'] == 'Тип ПО']
# Строим модель: зависимая переменная Count, фактор - Factor_Name
model_soft = ols('Count ~ C(Factor_Name)', data=df_soft_types).fit()
anova_soft = sm.stats.anova_lm(model_soft, typ=2)

print("--- Влияние фактора 'Тип ПО' ---")
# H0: Среднее число уязвимостей одинаково для всех типов ПО.
# H1: Существуют типы ПО со статистически значимо различающимся средним числом уязвимостей.
print(anova_soft)

# Рассчитываем R-квадрат (степень влияния)
r_squared_soft = anova_soft['sum_sq'][0] / (anova_soft['sum_sq'][0] + anova_soft['sum_sq'][1])
print(f"\nКоэффициент детерминации R² = {r_squared_soft:.2f}")
print(f"Вывод: {r_squared_soft:.0%} вариации в количестве уязвимостей объясняется различиями между типами ПО.")
if anova_soft['PR(>F)'][0] < 0.05:
    print("Результат: Влияние фактора 'Тип ПО' СТАТИСТИЧЕСКИ ЗНАЧИМО.\n")
else:
    print("Результат: Влияние фактора 'Тип ПО' НЕ является статистически значимым.\n")


# --- Анализ влияния фактора 'Тип ошибки (CWE)' ---
df_cwe_types = df1_2025[df1_2025['Factor_Category'] == 'Тип ошибки']
model_cwe = ols('Count ~ C(Factor_Name)', data=df_cwe_types).fit()
anova_cwe = sm.stats.anova_lm(model_cwe, typ=2)

print("--- Влияние фактора 'Тип ошибки (CWE)' ---")
# H0: Среднее число уязвимостей одинаково для всех типов ошибок CWE.
# H1: Существуют типы ошибок со статистически значимо различающимся средним числом уязвимостей.
print(anova_cwe)
r_squared_cwe = anova_cwe['sum_sq'][0] / (anova_cwe['sum_sq'][0] + anova_cwe['sum_sq'][1])
print(f"\nКоэффициент детерминации R² = {r_squared_cwe:.2f}")
print(f"Вывод: {r_squared_cwe:.0%} вариации в количестве уязвимостей объясняется различиями между типами ошибок.")
if anova_cwe['PR(>F)'][0] < 0.05:
    print("Результат: Влияние фактора 'Тип ошибки (CWE)' СТАТИСТИЧЕСКИ ЗНАЧИМО.\n")
else:
    print("Результат: Влияние фактора 'Тип ошибки (CWE)' НЕ является статистически значимым.\n")

# Цель: сравнить, какой из факторов оказывает БОЛЕЕ СИЛЬНОЕ влияние.
print("\n" + "="*50)
print(" ЗАДАЧА 1.2: СРАВНЕНИЕ СИЛЫ ВЛИЯНИЯ ФАКТОРОВ")
print("="*50 + "\n")

# Создаем объединенные данные для двухфакторного анализа
# (используем весь датасет df1_2025, где есть оба типа факторов)
model_two_factors = ols('Count ~ C(Factor_Category) + C(Month)', data=df1_2025).fit()
anova_two_factors = sm.stats.anova_lm(model_two_factors, typ=2)

print("--- Сравнение влияния 'Категории Фактора' (ПО vs Ошибка) и 'Месяца' ---")
# H0 для 'Категории': Тип ПО и Тип ошибки в среднем имеют одинаковое число уязвимостей.
# H0 для 'Месяца': Среднее число уязвимостей одинаково для всех месяцев.
print(anova_two_factors)
print("\nИнтерпретация: Сравниваем F-статистики для двух факторов.")
print("У какого фактора F-статистика больше (при p-value < 0.05), тот и оказывает более значимое влияние.")

# Цель: выяснить, есть ли совместное влияние факторов.
print("\n" + "="*50)
print(" ЗАДАЧА 1.3: АНАЛИЗ ВЗАИМОДЕЙСТВИЯ ФАКТОРОВ (2023-2025)")
print("="*50 + "\n")

# Фильтруем данные для анализа типов ошибок по годам и месяцам
df_cwe_multiyear = df1_multiyear[df1_multiyear['Factor_Category'] == 'Тип ошибки']

# Формула 'Count ~ C(Year) * C(Month)' проверяет:
# 1. Влияние 'Года' (C(Year))
# 2. Влияние 'Месяца' (C(Month))
# 3. Их взаимодействие (C(Year):C(Month))
model_interaction = ols('Count ~ C(Year) * C(Month)', data=df_cwe_multiyear).fit()
anova_interaction = sm.stats.anova_lm(model_interaction, typ=2)

print("--- Влияние 'Года', 'Месяца' и их ВЗАИМОДЕЙСТВИЯ на число уязвимостей типа CWE ---")
print(anova_interaction)
print("\nИнтерпретация:")
print("1. Смотрим на p-value для C(Year) и C(Month) - это их основное влияние.")
print("2. Самое важное: смотрим на p-value для 'C(Year):C(Month)'.")

interaction_p_value = anova_interaction.loc['C(Year):C(Month)', 'PR(>F)']
if interaction_p_value < 0.05:
    print("Результат: ВЗАИМОДЕЙСТВИЕ статистически значимо. Это означает, что месячная динамика числа уязвимостей отличается от года к году.")
else:
    print("Результат: Взаимодействие НЕ является статистически значимым. Влияние месяца примерно одинаково в разные годы.")

# Цель: найти связи между частотой возникновения разных типов уязвимостей.
print("\n" + "="*50)
print(" ЗАДАЧА 2: КОРРЕЛЯЦИЯ МЕЖДУ ТИПАМИ ОШИБОК")
print("="*50 + "\n")

# Убираем столбец 'Month', так как он не является переменной для корреляции
df_corr_cwe = df2_cwe.drop('Month', axis=1)

# 1. Расчет матрицы корреляций
corr_matrix = df_corr_cwe.corr()

print("--- Матрица корреляций Пирсона ---")
print(corr_matrix)

# 2. Визуализация с помощью тепловой карты
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Тепловая карта корреляций между типами уязвимостей (CWE)')
plt.show()

# 3. Проверка значимости корреляций (расчет p-value) - ИСПРАВЛЕННАЯ ВЕРСИЯ
def calculate_pvalues(df):
    dfcols = pd.DataFrame(columns=df.columns)
    pvalues = dfcols.transpose().join(dfcols, how='outer')
    for r in df.columns:
        for c in df.columns:
            # Используем .loc для надежного присваивания значения
            pvalues.loc[r, c] = round(pearsonr(df[r], df[c])[1], 4)
    return pvalues

p_values_matrix = calculate_pvalues(df_corr_cwe)
print("\n--- Матрица P-значений для коэффициентов корреляции (без предупреждений) ---")
print("(Если p-value < 0.05, то корреляция статистически значима)")
print(p_values_matrix)


# 4. Поиск пар с "очень сильной" связью (по шкале Чеддока |r| >= 0.9)
# Создаем маску для выбора только сильных корреляций
strong_corr_mask = (corr_matrix.abs() >= 0.9) & (corr_matrix.abs() < 1.0)
strong_pairs = corr_matrix[strong_corr_mask].stack().reset_index()
strong_pairs.columns = ['Тип ошибки 1', 'Тип ошибки 2', 'Коэффициент r']
# Удаляем дубликаты (пара A-B такая же, как B-A)
strong_pairs['sorted_pair'] = strong_pairs.apply(lambda row: tuple(sorted((row['Тип ошибки 1'], row['Тип ошибки 2']))), axis=1)
strong_pairs = strong_pairs.drop_duplicates('sorted_pair').drop('sorted_pair', axis=1)

print("\n--- Пары уязвимостей с ОЧЕНЬ СИЛЬНОЙ связью (|r| >= 0.9) ---")
if strong_pairs.empty:
    print("В данном наборе данных пар с очень сильной корреляцией не найдено.")
else:
    print(strong_pairs)

# ЗАДАЧА 3: АНАЛИЗ МЕТРИК ПРОИЗВОДИТЕЛЕЙ
print("\n" + "="*50)
print(" ЗАДАЧА 3: ЧАСТНАЯ И МНОЖЕСТВЕННАЯ КОРРЕЛЯЦИЯ")
print("="*50 + "\n")

# Для этой задачи нужна библиотека pingouin. Установим ее, если еще нет.
try:
    import pingouin as pg
except ImportError:
    print("Устанавливаем библиотеку pingouin...")
    !pip install pingouin
    import pingouin as pg


# 1. Простая парная корреляция для сравнения
print("--- Простая парная корреляция (для сравнения) ---")
simple_corr_vendors = df3_vendors[['Total_Vulns', 'Critical_Vulns', 'Incident_Vulns']].corr()
print(simple_corr_vendors)

# 2. Частная корреляция
# Цель: выяснить, какова связь, например, между Total_Vulns и Critical_Vulns,
# если убрать влияние переменной Incident_Vulns.
print("\n--- Матрица частных корреляций ---")
partial_corr_matrix = df3_vendors[['Total_Vulns', 'Critical_Vulns', 'Incident_Vulns']].pcorr()
print(partial_corr_matrix)
print("\nИнтерпретация: Сравните значения из этой таблицы с таблицей простой корреляции.")
print("Например, частная корреляция между Total_Vulns и Critical_Vulns показывает их связь, как если бы все производители имели одинаковое число инцидентов.")

# 3. Множественная корреляция
# Цель: выяснить, насколько хорошо две переменные (например, Critical и Incident)
# вместе объясняют изменчивость третьей переменной (Total_Vulns).

# Используем линейную регрессию, чтобы найти R-квадрат
from sklearn.linear_model import LinearRegression

# Подготовим данные:
# Отфильтруем строки, где Total_Vulns > 0, так как мы предсказываем именно эту переменную
df_regr = df3_vendors[df3_vendors['Total_Vulns'] > 0]
X = df_regr[['Critical_Vulns', 'Incident_Vulns']] # Независимые переменные
y = df_regr['Total_Vulns']                      # Зависимая переменная

# Строим и обучаем модель
model_regr = LinearRegression().fit(X, y)
# Коэффициент детерминации R²
r_squared = model_regr.score(X, y)
# Коэффициент множественной корреляции R - это корень из R²
multiple_corr_R = np.sqrt(r_squared)

print(f"\n--- Множественная корреляция ---")
print(f"Модель: Total_Vulns ~ Critical_Vulns + Incident_Vulns")
print(f"Коэффициент детерминации R-квадрат = {r_squared:.4f}")
print(f"Коэффициент множественной корреляции R = {multiple_corr_R:.4f}")
print(f"\nВывод: {r_squared:.0%} вариации в общем числе уязвимостей можно объяснить")
print("линейной зависимостью от числа критических уязвимостей и уязвимостей, связанных с инцидентами.")